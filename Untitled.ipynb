{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad82621-ec0f-42f6-a329-f8d3856e180e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "lfw_dataset_dir = \"/home/osman/PycharmProjects/ComputerVision/facenet-official/facenet/datasets/aligned_lfw\"\n",
    "train_dir = \"/home/osman/PycharmProjects/ComputerVision/facenet-official/facenet/datasets/aligned_lfw_train\"\n",
    "validation_dir = \"/home/osman/PycharmProjects/ComputerVision/facenet-official/facenet/datasets/aligned_lfw_val\"\n",
    "validation_ratio = 0.2  # 20% of images for validation\n",
    "\n",
    "# Create the training and validation directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(validation_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each person's folder in the LFW dataset\n",
    "for person_folder in os.listdir(lfw_dataset_dir):\n",
    "    person_path = os.path.join(lfw_dataset_dir, person_folder)\n",
    "    if not os.path.isdir(person_path):\n",
    "        continue\n",
    "\n",
    "    # Get the list of image files in the person's folder\n",
    "    image_files = os.listdir(person_path)\n",
    "\n",
    "    # Skip the person if there is only one image\n",
    "    if len(image_files) <= 1:\n",
    "        continue\n",
    "\n",
    "    # Create a separate folder for the person in the training directory\n",
    "    train_person_folder = os.path.join(train_dir, person_folder)\n",
    "    os.makedirs(train_person_folder, exist_ok=True)\n",
    "\n",
    "    # Calculate the number of images for validation based on the ratio\n",
    "    num_validation_images = int(len(image_files) * validation_ratio)\n",
    "\n",
    "    # Randomly select images for validation\n",
    "    validation_images = random.sample(image_files, num_validation_images)\n",
    "\n",
    "    # Copy the selected validation images to the validation folder\n",
    "    validation_person_folder = os.path.join(validation_dir, person_folder)\n",
    "    os.makedirs(validation_person_folder, exist_ok=True)\n",
    "    for image_file in validation_images:\n",
    "        image_path = os.path.join(person_path, image_file)\n",
    "        shutil.copy(image_path, os.path.join(validation_person_folder, image_file))\n",
    "\n",
    "    # Copy the remaining images to the training folder\n",
    "    for image_file in image_files:\n",
    "        if image_file not in validation_images:\n",
    "            image_path = os.path.join(person_path, image_file)\n",
    "            shutil.copy(image_path, os.path.join(train_person_folder, image_file))\n",
    "            \n",
    "            \n",
    "# Remove empty folders from the validation directory\n",
    "for person_folder in os.listdir(validation_dir):\n",
    "    person_path = os.path.join(validation_dir, person_folder)\n",
    "    if os.path.isdir(person_path) and not os.listdir(person_path):\n",
    "        os.rmdir(person_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1549f954-af56-48c5-bb5b-863fb0ecb199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "#os.remove(path) #Delete file\n",
    "#os.removedirs(path) #Delete empty folder\n",
    "\n",
    "\n",
    "def find_corrupt(folder_path):\n",
    "    data_dir = folder_path\n",
    "    flds = os.listdir(data_dir)\n",
    "\n",
    "    for fld in flds:\n",
    "        sub_flds = os.listdir(data_dir + '/' + fld)\n",
    "        try:\n",
    "            for i in sub_flds:\n",
    "                i_path = data_dir + '/' + fld + '/' + i\n",
    "                img = imread(i_path)\n",
    "                #print(np.shape(img))\n",
    "        except:\n",
    "            print(data_dir + '/' + fld)\n",
    "            shutil.rmtree(data_dir + '/' + fld)  #Delete folders\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f44d6257-c9df-4108-98e0-60120f523082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/frt/ConvertedToTf2/datasets/aligned_casia/008016\n",
      "/home/frt/ConvertedToTf2/datasets/aligned_casia/001183\n"
     ]
    }
   ],
   "source": [
    "find_corrupt('/home/frt/ConvertedToTf2/datasets/aligned_casia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ada2366d-2c06-4922-8d4d-26ba3b0336a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /home/frt/anaconda3/lib/python3.10/site-packages (0.19.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/frt/anaconda3/lib/python3.10/site-packages (from scikit-image) (22.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/frt/anaconda3/lib/python3.10/site-packages (from scikit-image) (2.8.4)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/frt/anaconda3/lib/python3.10/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/frt/anaconda3/lib/python3.10/site-packages (from scikit-image) (2.26.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/frt/anaconda3/lib/python3.10/site-packages (from scikit-image) (1.8.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/frt/anaconda3/lib/python3.10/site-packages (from scikit-image) (2021.7.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/frt/anaconda3/lib/python3.10/site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/frt/anaconda3/lib/python3.10/site-packages (from scikit-image) (1.22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "771e695f-6e4b-4a7b-a291-f30e8a624058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d32ca91e-487f-41b4-bdb3-c2480c2d0644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_97331/3890759990.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU available: True\n",
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 15:33:56.034751: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-19 15:33:56.139072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-19 15:33:56.152599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-19 15:33:56.152870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-19 15:33:56.534900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-19 15:33:56.535063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-19 15:33:56.535160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-19 15:33:56.535265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /device:GPU:0 with 670 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-06-19 15:33:56.537415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-19 15:33:56.537561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-19 15:33:56.537654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Check if TensorFlow is using GPU\n",
    "print(\"GPU available:\", tf.test.is_gpu_available())\n",
    "\n",
    "# Check the list of available GPUs\n",
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a123083d-383d-450f-94b5-b2114b1ba8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"src/align/align_dataset_mtcnn.py\", line 34, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/__init__.py\", line 24, in <module>\n",
      "    from tensorflow.python import *  # pylint: disable=redefined-builtin\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"/home/frt/anaconda3/envs/py36/lib/python3.6/imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/install_sources#common_installation_problems\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    }
   ],
   "source": [
    "!python src/align/align_dataset_mtcnn.py /home/frt/facenet-official/facenet/datasets/CASIA-WebFace_cropped /home/frt/facenet-official/facenet/datasets/aligned_casia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dabf5f28-2582-465c-bed8-23a8342625fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:19:46.440234: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-22 15:19:46.639109: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-22 15:19:46.705544: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-22 15:19:47.284769: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-06-22 15:19:47.284835: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-06-22 15:19:47.284840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-06-22 15:19:48.013078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-22 15:19:48.026745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-22 15:19:48.027094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.10.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir /home/frt/ConvertedToTf2/logs/facenet --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fe3d455-0967-4fe9-9250-2fd0385cf299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 16:44:24.445696: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ebc9f2-cdfb-4afb-9584-d4f99c01aad8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2717469298.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    model = /home/frt/ConvertedToTf2/src/models.inception_resnet_v1\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = /home/frt/ConvertedToTf2/src/models.inception_resnet_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d3e9ff-4d6c-4091-826d-b9a997773c88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No model config found in the file at <tensorflow.python.platform.gfile.GFile object at 0x7fc5fa60c430>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_new \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/frt/ConvertedToTf2/logs/facenet/20230621-153610/stat.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/saving/hdf5_format.py:182\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    180\u001b[0m model_config \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mattrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo model config found in the file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model_config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    184\u001b[0m   model_config \u001b[38;5;241m=\u001b[39m model_config\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No model config found in the file at <tensorflow.python.platform.gfile.GFile object at 0x7fc5fa60c430>."
     ]
    }
   ],
   "source": [
    "model_new = load_model(\"/home/frt/ConvertedToTf2/logs/facenet/20230621-153610/stat.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
