arguments: src/train_softmax.py --logs_base_dir /home/osman/PycharmProjects/ComputerVision/facenet-official/facenet/logs/facenet --models_base_dir /home/osman/PycharmProjects/ComputerVision/facenet-official/facenet/models/facenet --data_dir /home/osman/PycharmProjects/ComputerVision/facenet-official/facenet/datasets/aligned_lfw --image_size 160 --model_def models.inception_resnet_v1 --optimizer ADAM --learning_rate -1 --max_nrof_epochs 10 --keep_probability 0.8 --random_crop --random_flip --use_fixed_image_standardization --learning_rate_schedule_file /home/osman/PycharmProjects/ComputerVision/facenet-official/facenet/data/learning_rate_schedule_classifier_casia.txt --weight_decay 5e-4 --embedding_size 512
--------------------
tensorflow version: 1.7.0
--------------------
git hash: b'096ed770f163957c1e56efa7feeb194773920f6e'
--------------------
b'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\nindex 7d5e735..f419e58 100644\n--- a/src/align/align_dataset_mtcnn.py\n+++ b/src/align/align_dataset_mtcnn.py\n@@ -26,6 +26,8 @@ from __future__ import division\n from __future__ import print_function\n \n from scipy import misc\n+from skimage.transform import resize\n+import imageio\n import sys\n import os\n import argparse\n@@ -80,7 +82,9 @@ def main(args):\n                 print(image_path)\n                 if not os.path.exists(output_filename):\n                     try:\n-                        img = misc.imread(image_path)\n+                        # img = misc.imread(image_path)\n+                        ########### amar change kora #######\n+                        img = imageio.imread(image_path)\n                     except (IOError, ValueError, IndexError) as e:\n                         errorMessage = \'{}: {}\'.format(image_path, e)\n                         print(errorMessage)\n@@ -121,14 +125,14 @@ def main(args):\n                                 bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n                                 bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n                                 cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n-                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n+                                scaled = resize(cropped, (args.image_size, args.image_size), mode=\'reflect\')\n                                 nrof_successfully_aligned += 1\n                                 filename_base, file_extension = os.path.splitext(output_filename)\n                                 if args.detect_multiple_faces:\n                                     output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\n                                 else:\n                                     output_filename_n = "{}{}".format(filename_base, file_extension)\n-                                misc.imsave(output_filename_n, scaled)\n+                                imageio.imwrite(output_filename_n, scaled)\n                                 text_file.write(\'%s %d %d %d %d\\n\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\n                         else:\n                             print(\'Unable to align "%s"\' % image_path)\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\nindex 7f98ca7..58a56f6 100644\n--- a/src/align/detect_face.py\n+++ b/src/align/detect_face.py\n@@ -82,7 +82,10 @@ class Network(object):\n         session: The current TensorFlow session\n         ignore_missing: If true, serialized weights for missing layers are ignored.\n         """\n-        data_dict = np.load(data_path, encoding=\'latin1\').item() #pylint: disable=no-member\n+        # data_dict = np.load(data_path, encoding=\'latin1\').item() #pylint: disable=no-member\n+        \n+        #########amar change ########\n+        data_dict = np.load(data_path, allow_pickle = True, encoding=\'latin1\').item()\n \n         for op_name in data_dict:\n             with tf.variable_scope(op_name, reuse=True):'